{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To restart remote kernels run code below before restarting this kernel\n",
    "rc.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# to enter kernel qtconsole run code below\n",
    "%%px --targets 0 \n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "par_dir = os.path.split(os.getcwd())[0]\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "# sys.path.append(r'/Users/artemgolovizin/GitHub')\n",
    "from scipy.optimize import curve_fit\n",
    "import inspect\n",
    "import pickle\n",
    "import imp\n",
    "import re\n",
    "\n",
    "from IPython.html import widgets\n",
    "from IPython.display import display\n",
    "from IPython.html.widgets import interact, interactive, fixed\n",
    "\n",
    "from IPython import parallel\n",
    "\n",
    "import thulium_python_lib.image_processing_new as impr\n",
    "rc1 = parallel.Client()\n",
    "lview = rc1.load_balanced_view()\n",
    "dview = rc1.direct_view()\n",
    "with dview.sync_imports():\n",
    "    import sys, os    \n",
    "dview['par_dir'] = par_dir\n",
    "%px if par_dir not in sys.path: sys.path.append(par_dir)\n",
    "#%px if r'/Users/artemgolovizin/GitHub' not in sys.path: sys.path.append(r'/Users/artemgolovizin/GitHub')\n",
    "%px import thulium_python_lib.image_processing_new as impr\n",
    "%px import imp\n",
    "%px from IPython.parallel import bind_kernel; bind_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to reload library on remote and local engine\n",
    "#%px imp.reload(impr)\n",
    "#imp.reload(impr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_decay(t, N0, tau, background):\n",
    "    return N0 * exp(- t / tau) + background\n",
    "def exp_decay_no_bg(t, N0, tau):\n",
    "    return N0 * exp(- t / tau)\n",
    "def cloud_expansion(t, T, r0, t0):\n",
    "    k_b = 1.38e-23\n",
    "    m = 169 * 1.66e-27\n",
    "    return sqrt( r0**2 + 2 * k_b * T * (t + t0)**2 / m)\n",
    "def exp_grouth(t, N0, tau, background):\n",
    "    return N0 * ( 1 - exp( - t / tau)) + 0*background\n",
    "# function to convert arbitrary units to atoms number\n",
    "convert_N_atoms = impr.N_atoms(width=0.5, delta = 5)\n",
    "\n",
    "def feshbah_calibration(folder, data_dict):\n",
    "    \"\"\"gets folder name, which has 'conf=BH(SH)' to detect which coil current was scanned and 'offset=value' to calculate\n",
    "    offset field (produced with another coil) \n",
    "    second parameter is data_dictionary to modify\"\"\"\n",
    "    coil_dict = dict(BH=10.2, SH=0.25)\n",
    "    reverse_coil_dict = dict(BH='SH', SH='BH')\n",
    "    coeff = 1\n",
    "    offset = 0\n",
    "    for s0 in folder.rstrip(r'\\/ ').split():\n",
    "        if '=' in s0:\n",
    "            s1 = s0.split('=')\n",
    "            if s1[0] == 'conf':\n",
    "                coeff = coil_dict[s1[1]]\n",
    "                offset_coeff = coil_dict[reverse_coil_dict[s1[1]]]\n",
    "            if s1[0] == 'offset':\n",
    "                offset = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", s1[1])[0]) * offset_coeff\n",
    "    data_dict['x'] = data_dict['x'] * coeff + offset\n",
    "    \n",
    "def construct_fit_description(fit_func, popt_T):\n",
    "    \"\"\"constructs a set of string of type 'variable=value\\n' for all [1:] function variables\"\"\"\n",
    "    res = ''\n",
    "    for item in zip(inspect.getargspec(fit_func)[0][1:], popt_T):\n",
    "        res += str(item[0]) + ' = ' + \"%.2f\"%(item[1]) + '\\n'\n",
    "    res = res.rstrip('\\n')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now:\n",
    "### Constract loader and averager \n",
    "For available parameters see help('instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader  = impr.Load_Image(dview)\n",
    "averager = impr.Avr_Image(dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting directory to work with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os.chdir(r'D:\\!Data\\2015_07_01')\n",
    "os.chdir(r'\\\\BIGONE\\!Data\\2015_07_01')\n",
    "print('Current directory', os.getcwd());\n",
    "# Create folder 'Figures' for saving individual plot\n",
    "if not os.path.exists('Figures'):\n",
    "    os.makedirs('Figures')\n",
    "    print('Folder Figures has been created')\n",
    "    \n",
    "working_directory = ''\n",
    "folder = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Set measurement folder \n",
    "#### Set date of measurement directory and create folder Figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirs = [x for x in os.listdir() if re.match('\\d',x)]\n",
    "dirs.reverse()\n",
    "@interact(folder_=dirs)\n",
    "def h(folder_=folder):\n",
    "    global working_directory\n",
    "    global folder\n",
    "    folder = folder_\n",
    "    working_directory = os.path.join(os.getcwd(),folder)\n",
    "    print('Working directory', working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downloading images\n",
    "all_data = loader(working_directory,lview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rearranging to dictionary\n",
    "dataD = impr.rearrange_data(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sifting(filtering) data - removing empty images  !!! DOES NOTE WORKS NOW\n",
    "#impr.sift(dataD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for plotting sifted image\n",
    "#imshow(imread('1 от частоты амплитудной модуляции аома верди (5) 3.9W/26ms/2_1.png'))\n",
    "#colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# averaging data\n",
    "avr_dataD = averager(dataD,lview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After above, we can analize our data \n",
    "#### Construct  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shot_typeN = 1\n",
    "# first set of data  - Temperature X\n",
    "d1 = impr.get_avr_data_for_plot(avr_dataD, shot_typeN, impr.real_size, 'fit1D_x',2)\n",
    "d1['fmt']='ro'\n",
    "d1['label']='fit1D_x'\n",
    "#impr.drop_by_number(d1,5)\n",
    "#impr.drop_by_x(d1,18,20)\n",
    "\n",
    "# second set of data  - Temperature Y\n",
    "d2 = impr.get_avr_data_for_plot(avr_dataD, shot_typeN, impr.real_size, 'fit1D_y',2)\n",
    "d2['fmt']='bo'\n",
    "d2['label'] = 'fit1D_y'\n",
    "#impr.drop_by_number(d2,5)\n",
    "\n",
    "# third set of data - number of atoms \n",
    "d4 = impr.get_avr_data_for_plot(avr_dataD, shot_typeN, impr.real_size, 'fit1D_y',1)\n",
    "d4['fmt']='bo'\n",
    "d4['label']='fit1D_x'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit_func - which function to use to fit data\n",
    "fit_func = cloud_expansion\n",
    "popt_T, pcov_T = curve_fit(fit_func, d1['x'], d1['y'], p0=(d1['y'][0],20,0))\n",
    "print('Fit parameters',*list(zip(inspect.getargspec(fit_func)[0][1:], popt_T)))\n",
    "popt_T2, pcov_T2 = curve_fit(fit_func, d2['x'], d2['y'], p0=(d2['y'][0], 20,0))\n",
    "print('Fit parameters',*list(zip(inspect.getargspec(fit_func)[0][1:], popt_T2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main plot (1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = subplots()\n",
    "ax1.errorbar(**d2)\n",
    "ax1.errorbar(**d1)\n",
    "\n",
    "ax1.plot(linspace(min(d1['x']),max(d1['x']),100), fit_func(linspace(min(d1['x']),max(d1['x']),100),*popt_T),'k', label='fit X')\n",
    "ax1.plot(linspace(min(d2['x']),max(d2['x']),100), fit_func(linspace(min(d2['x']),max(d2['x']),100),*popt_T2),'k', label='fit Y')\n",
    "\n",
    "ax1.set_xlabel('time of flight, ms')\n",
    "ax1.set_ylabel('Cloud radius, um')\n",
    "ax1.set_title(folder)\n",
    "ax1.set_ylim(bottom=0)\n",
    "ax1.legend(loc=4)\n",
    "fit_label='Tx  =%.2f uK\\nTy = %.2f uK' % (popt_T[0],popt_T2[0])\n",
    "ax1.text(0.05,0.8,fit_label,transform=ax1.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main plot (2)  - number of atoms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cloud_drop(t, y0, v0, g):\n",
    "    return y0 + v0*t + g*t**2/2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig3, ax3 = subplots()\n",
    "ax3.errorbar(**d4)\n",
    "ax1.set_xlabel('time of flight, ms')\n",
    "ax3.set_ylabel('Number of atoms')\n",
    "ax3.set_title('Number of atoms for ' + folder)\n",
    "ax3.set_ylim(bottom=0)\n",
    "ax3.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3, ax3 = subplots()\n",
    "ax3.errorbar(**d4)\n",
    "ax1.set_xlabel('time of flight, ms')\n",
    "ax3.set_ylabel('Number of atoms')\n",
    "ax3.set_title('Number of atoms for ' + folder)\n",
    "ax3.set_ylim(bottom=0)\n",
    "ax3.legend(loc=4)\n",
    "fit_func = cloud_drop\n",
    "popt, pcov = curve_fit(fit_func, d4['x'], d4['y'], p0=(d4['y'][0],0,10))\n",
    "ax3.plot(linspace(min(d4['x']),max(d4['x']),100), fit_func(linspace(min(d4['x']),max(d4['x']),100),*popt),'k', label='fit Y')\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of each image - to check if everything is ok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each picture\n",
    "d3 = dict()\n",
    "d3['x'],d3['y'] = impr.constract_data(dataD, shot_typeN, 'fit1D_x',2)\n",
    "\n",
    "fig2, ax2 = subplots()\n",
    "ax2.errorbar(fmt='o',**d3)\n",
    "ax2.set_ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save plots to folder 'Figures' (if in outter directory) and data to file 'all_N_atoms_data.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if folder != '':\n",
    "    fig1.savefig(os.path.join('Figures',folder.rstrip(r'\\/ ')+'--tempearture.png'))\n",
    "    # if one need to save atom nubmer:\n",
    "    #fig3.savefig(os.path.join('Figures',folder.rstrip(r'\\/ ')+'--N_atoms.png'))\n",
    "    try:\n",
    "        with open('all_temperature_data.txt', 'rb') as handle:\n",
    "            res_dict = pickle.loads(handle.read())\n",
    "    except FileNotFoundError:\n",
    "        res_dict = {}\n",
    "    except EOFError:\n",
    "        res_dict = {}\n",
    "    descript = 'Description: [0],[1] - x,y data for Tx, [2],[3] - x,y data for Ty, [4],[5] - ' + ' fit to this data'\n",
    "    res_dict[folder.rstrip(r'\\/ ')]=(d1['x'], d1['y'],d2['x'], d2['y'],popt_T,popt_T2,descript)\n",
    "    with open('all_temperature_data.txt', 'wb') as handle:\n",
    "        pickle.dump(res_dict, handle)\n",
    "    print('Figure and data saved!!!')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# plot a sum over one axis\n",
    "plot(sum(avr_dataD[5][1].image,1))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize average data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#norm_avr_dataD = normalise_avr_image(avr_dataD, 1, 2, 'x_data_fit',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#norm_dataD = normalise_individual_image(dataD, 1, 2, 'x_data_fit',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And do smth with this data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# to transform to executable code choose Cell->Cell Type->Code\n",
    "x_data_x,n_atoms_x = constract_data(norm_avr_dataD, 1, 'x_data_fit',0)\n",
    "x_data_y,n_atoms_y = constract_data(norm_avr_dataD, 1, 'y_data_fit',0)\n",
    "popt_T, pcov_T = curve_fit(exp_decay, x_data_x, n_atoms_x, p0=(n_atoms_x[0], 100, 0))\n",
    "print('Fit parameters',list(zip(inspect.getargspec(exp_decay)[0][1:], popt_T)))\n",
    "fig_T, ax_T = subplots(1,1)\n",
    "ax_T.plot(x_data_x, n_atoms_x, 'ro', label='n_atoms_x')\n",
    "ax_T.plot(x_data_y, n_atoms_y, 'bo', label='n_atoms_y')\n",
    "x_dat = linspace(0,max(x_data_x),100)\n",
    "ax_T.plot(x_dat, exp_decay(x_dat,*popt_T),'k', label='exp fit X')\n",
    "ax_T.set_xlabel('time, ms')\n",
    "ax_T.set_ylabel('N atoms, a.u.')\n",
    "ax_T.set_title('N atoms after norm')\n",
    "ax_T.set_ylim(bottom=0)\n",
    "ax_T.legend(loc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at second shot_typeN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#x_data,y_data = constract_data(avr_dataD, 2, 'total')\n",
    "#plot(append(x_data, 0), append(y_data,0), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
